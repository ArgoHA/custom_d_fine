project_name: TACO # for wandb
exp_name: seg_l_high # experiment name

exp: ${exp_name}_${now_dir}

model_name: l # model size (n, s, m, l, x)
task: segment # detect or segment

train:
  ### Paths ###
  root: /home/argo/Desktop/Projects/taco # project root with dataset and outputs
  pretrained_dataset: coco # coco, obj2coco
  pretrained_model_path: pretrained/dfine_${model_name}_${train.pretrained_dataset}.pth # dfine_m_obj2coco.pth

  data_path: ${train.root}/data/dataset # path to dataset
  path_to_test_data: ${train.root}/data/test  # path to test set, used in infer script
  path_to_save: ${train.root}/output/models/${exp} # where to save output

  debug_img_path: ${train.root}/output/debug_images
  eval_preds_path: ${train.root}/output/eval_preds
  bench_img_path: ${train.root}/output/bench_imgs
  infer_path: ${train.root}/output/infer

  ### Configs ###
  use_wandb: False
  device: cuda
  label_to_name: # dataset's classes
    0: aerosol
    1: aluminium_blister_pack
    2: aluminium_foil
    3: battery
    4: broken_glass
    5: carded_blister_pack
    6: cigarette
    7: clear_plastic_bottle
    8: corrugated_carton
    9: crisp_packet
    10: disposable_food_container
    11: disposable_plastic_cup
    12: drink_can
    13: drink_carton
    14: egg_carton
    15: foam_cup
    16: foam_food_container
    17: food_can
    18: food_waste
    19: garbage_bag
    20: glass_bottle
    21: glass_cup
    22: glass_jar
    23: magazine_paper
    24: meal_carton
    25: metal_bottle_cap
    26: metal_lid
    27: normal_paper
    28: other_carton
    29: other_plastic
    30: other_plastic_bottle
    31: other_plastic_container
    32: other_plastic_cup
    33: other_plastic_wrapper
    34: paper_bag
    35: paper_cup
    36: paper_straw
    37: pizza_box
    38: plastic_bottle_cap
    39: plastic_film
    40: plastic_glooves
    41: plastic_lid
    42: plastic_straw
    43: plastic_utensils
    44: polypropylene_bag
    45: pop_tab
    46: rope&strings
    47: scrap_metal
    48: shoe
    49: single-use_carrier_bag
    50: six_pack_rings
    51: spread_tub
    52: squeezable_tube
    53: styrofoam_piece
    54: tissues
    55: toilet_tube
    56: tupperware
    57: unlabeled_litter
    58: wrapping_paper


  use_one_class: False

  ### Distributed Training (DDP) ###
  ddp:
    enabled: False  # set to true to use multi-GPU
    n_gpus: 2  # how many GPUs / processes per node for torchrun

  decision_metrics: # f1, iou, mAP_50, mAP_50_95, mAP_50_mask, mAP_50_95_mask
  - f1
  - mAP_50 # will be swapped with mask version for task = segment
  - iou

  img_size: [640, 640] # (h, w)
  keep_ratio: False # image aspect ratio, if True - image will be padded
  to_visualize_eval: True # save images with gt and preds
  debug_img_processing: True # save images after preprocessing

  amp_enabled: True # use automatic mixed precision
  clip_max_norm: 0.1 # gradient clipping

  batch_size: 6 # physical, should fit on the device. In DDP used per GPU
  b_accum_steps: 1 # grad accumulation (n * bs)
  epochs: 50
  early_stopping: 0 # 0 - no early stopping
  ignore_background_epochs: 0 # background images are not used for N epochs in train set
  num_workers: 12 # In DDP used per GPU
  mask_batch_size: 150 # number of images to process at once when computing mask metrics

  ### Validation ###
  conf_thresh: 0.5
  iou_thresh: 0.5

  ### EMA ###
  use_ema: True # use exponential moving average model
  ema_momentum: 0.9998

  ### Optimizer and Scheduler ###
  use_scheduler: True
  base_lr: ${train.lrs.${model_name}.base_lr}
  backbone_lr: ${train.lrs.${model_name}.backbone_lr}
  cycler_pct_start: 0.1
  weight_decay: 0.000125
  betas: [0.9, 0.999]
  label_smoothing: 0.0

  ### Augs ###
  mosaic_augs: # not recommended for segmentation
    mosaic_prob: 0.8 # set to 0 to disable
    no_mosaic_epochs: 5
    mosaic_scale: [0.5, 1.5]
    degrees: 0.0 # not recommended if bbox precision is critical
    translate: 0.2
    shear: 2.0

  augs:
    rotation_degree: 10 # maximum +- rotation
    rotation_p: 0.05 # probability of the rotation (with above degree)
    multiscale_prob: 0.0
    rotate_90: 0.05
    left_right_flip: 0.3
    up_down_flip: 0.0
    to_gray: 0.01
    blur: 0.01
    gamma: 0.02
    brightness: 0.02
    noise: 0.01
    coarse_dropout: 0.0

  ### Reproducibility ###
  seed: 42
  cudnn_fixed: False

  ### Recommended learning rates ###
  lrs:
    n:
      backbone_lr: 0.0004
      base_lr: 0.0008
    s:
      backbone_lr: 0.00006  # can setup up to 0.0002
      base_lr: 0.00025  # 0.0004
    m:
      backbone_lr: 0.00002  # 0.000025
      base_lr: 0.00015  # 0.00025
    l:
      backbone_lr: 0.00001 # 0.00000625 - 0.0000125
      base_lr: 0.00016 # 0.000125 - 0.00025
    x:
      backbone_lr: 0.000002  # 0.0000015 - 0.0000025
      base_lr: 0.0002  # 0.0001 - 0.00025


split:
  ignore_negatives: False # only use images with labels
  shuffle: True
  train_split: 0.85
  val_split: 0.15 # test_split = 1 - train_split - val_split


export: # TensorRT must be done on the inference device
  half: True # tensorrt, openvino
  max_batch_size: 1 # torch, tensorrt, openvino
  dynamic_input: False
  ov_int8_max_drop: 0.025


infer:
  to_crop: True  # if True - saves crops of detected objects
  paddings: # if int - amount of pixes, if float - percentage of image size
    w: 0.05
    h: 0.05


### service ###
defaults:
  - _self_
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

hydra:
  output_subdir: null
  run:
    dir: .

now_dir: &nowdir ${now:%Y-%m-%d}
